{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq8U3BtmhtRx"
   },
   "source": [
    "\n",
    "# **Running Pyspark in Colab (Due date: February 10 at 1 p.m.)**\n",
    "PySpark is the Python API for Spark, which is an important tool in Big Data. To run spark in Colab, we need to first install pyspark package and Findspark to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab. Follow the steps to install the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lh5NCoc8fsSO",
    "outputId": "8f02bcfe-a9d9-4bb8-9f25-de8159e21ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9.3\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 58.4 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=869e3319e343c5ebff8825208f546dd180bb5d6fda52be7c32ac00c971ca3d39\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwrqMk3HiMiE"
   },
   "source": [
    "Run a local spark session to test your installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9_Uz1NL4gHFx"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEb4HTRwiaJx"
   },
   "source": [
    "Congrats! Your Colab is ready to run Pyspark.\n",
    "\n",
    "# Read input text file to RDD \n",
    "\n",
    "The first step to use Pyspark is reading input text file to resilient distributed dataset (RDD) provides by Spark as the primary abstraction.\n",
    "\n",
    "Download the input data from [here](https://github.com/umddm/ECE795_Homeworks_Spring2022/blob/homework_1/StudentsPerformance.csv) and keep it in the Colab document by the following command. The input data can also be downloaded from the blackboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNsM_jHqrjBg"
   },
   "source": [
    "Check the input data correctly in the system by the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m606eNuQgA82",
    "outputId": "7ae5c272-1f3f-4515-d841-5081e3f51ca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  StudentsPerformance.csv  StudentsPerformance.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21D9EANUvnwF"
   },
   "source": [
    "Now that we have input data, we can start to do the homework. \n",
    "\n",
    "## Question 1: Use sc.textFile to read the provided input data and split different fields.\n",
    "\n",
    "### Expected output of rdd.take(10):\n",
    "```\n",
    "['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score']\n",
    "['female', 'group B', \"bachelor's degree\", 'standard', 'none', '72', '72', '74']\n",
    "['female', 'group C', 'some college', 'standard', 'completed', '69', '90', '88']\n",
    "['female', 'group B', \"master's degree\", 'standard', 'none', '90', '95', '93']\n",
    "['male', 'group A', \"associate's degree\", 'free/reduced', 'none', '47', '57', '44']\n",
    "['male', 'group C', 'some college', 'standard', 'none', '76', '78', '75']\n",
    "['female', 'group B', \"associate's degree\", 'standard', 'none', '71', '83', '78']\n",
    "['female', 'group B', 'some college', 'standard', 'completed', '88', '95', '92']\n",
    "['male', 'group B', 'some college', 'free/reduced', 'none', '40', '43', '39']\n",
    "['male', 'group D', 'high school', 'free/reduced', 'completed', '64', '64', '67']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZeJ7WQCgM8g",
    "outputId": "fc183fe4-927c-45c4-ec32-1cdbbd7b48f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender’,’race/ethnicity’,’parental level of education’,’lunch’,’test preparation course’,’math score’,’reading score’,’writing score']\n",
      "['female’,’group B’,\"bachelor’s degree\",’standard’,’none’,’72’,’72’,’74']\n",
      "['female’,’group C’,’some college’,’standard’,’completed’,’69’,’90’,’88']\n",
      "['female’,’group B’,\"master’s degree\",’standard’,’none’,’90’,’95’,’93']\n",
      "['male’,’group A’,\"associate’s degree\",’free/reduced’,’none’,’47’,’57’,’44']\n",
      "['male’,’group C’,’some college’,’standard’,’none’,’76’,’78’,’75']\n",
      "['female’,’group B’,\"associate’s degree\",’standard’,’none’,’71’,’83’,’78']\n",
      "['female’,’group B’,’some college’,’standard’,’completed’,’88’,’95’,’92']\n",
      "['male’,’group B’,’some college’,’free/reduced’,’none’,’40’,’43’,’39']\n",
      "['male’,’group D’,’high school’,’free/reduced’,’completed’,’64’,’64’,’67']\n"
     ]
    }
   ],
   "source": [
    "#sc.textFile\n",
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "#Question_1:  \n",
    "#Fill out here\n",
    "\n",
    "rdd = sc.textFile('./StudentsPerformance.txt').map(lambda x: x.replace(\"\\\"\",\"'\")).map(lambda line: line.split('\\t'))  # \"replace \"\"\n",
    "#rdd.take(10)\n",
    "for line in rdd.take(10):\n",
    "    print (line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3vYyp5dwOm_"
   },
   "source": [
    "## Question 2: Convert all the elements in the last three columns of the RDD to integer type and save in \"MathScore.txt\", \"ReadingScore.txt\" and \"WritingScore.txt\".\n",
    "\n",
    "Please do not upload the generated output files to Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fSoAB0Bg7jUk"
   },
   "outputs": [],
   "source": [
    "#Question_2  Test\n",
    "#Fill out here\n",
    "\n",
    "mydata = sc.textFile('./StudentsPerformance.txt')\n",
    "#delete header\n",
    "header = mydata.first()\n",
    "mydata = mydata.filter(lambda line: line != header)\n",
    "#mydata.first()   # test delete header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Eja1BLiaTThT"
   },
   "outputs": [],
   "source": [
    "#Question_2\n",
    "#Fill out here\n",
    "\n",
    "MathScore = mydata.map(lambda x:int(x.split(\",\")[5].replace(\"\\\"\",\"\")))  \n",
    "MathScore.repartition(1).saveAsTextFile(\"MathScore.txt\")   # saveAsTextFile(\"MathScore.txt\")\n",
    "\n",
    "ReadingScore = mydata.map(lambda x:int(x.split(\",\")[6].replace(\"\\\"\",\"\")))\n",
    "ReadingScore.repartition(1).saveAsTextFile(\"ReadingScore.txt\")   # saveAsTextFile(\"ReadingScore.txt\")\n",
    "\n",
    "WritingScore = mydata.map(lambda x:int(x.split(\",\")[7].replace(\"\\\"\",\"\")))\n",
    "WritingScore.repartition(1).saveAsTextFile(\"WritingScore.txt\")   # saveAsTextFile(\"WritingScore.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kam8VOngOIVI",
    "outputId": "c8fb9fc1-2658-4f0d-8c6e-ad82c5e5417f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathScore.txt\t  sample_data\t\t   StudentsPerformance.txt\n",
      "ReadingScore.txt  StudentsPerformance.csv  WritingScore.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aoBtwGIrVUEC",
    "outputId": "9c889761-a3fd-4bc6-9123-4aa9a8d03238"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['72', '69', '90', '47', '76', '71', '88', '40', '64', '38']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question_2\n",
    "# Read .txt Test\n",
    "\n",
    "read_rdd = sc.textFile(\"MathScore.txt\")  # Read MathScore.txt Test\n",
    "read_rdd.collect()\n",
    "read_rdd.take(10)   # Test MathScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FHVHVQjd4P1"
   },
   "source": [
    "## Question 3: Please output the number of elements in the RDD with 'A', 'degree' and 'school'.\n",
    "For example, a valid element can be 'Group A', 'associate's degree', 'high school' or 'Apple' ('A' is a substring of the words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJsxix2Xd3-Q",
    "outputId": "6b981cc2-12b7-48bd-ea13-d9759aee9366"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question_3\n",
    "#Fill out here\n",
    "\n",
    "# Output the number of elements in the RDD with 'A'\n",
    "mydata = sc.textFile('./StudentsPerformance.txt')\n",
    "A_count = mydata.filter(lambda x: \"A\" in x).count()\n",
    "A_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Uv8byX9OkV4",
    "outputId": "be62f503-d73b-4f45-a167-ddc194e1fd08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the number of elements in the RDD with 'degree'\n",
    "mydata = sc.textFile('./StudentsPerformance.txt')\n",
    "degree_count = mydata.filter(lambda x: \"degree\" in x).count()\n",
    "degree_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uR4qo7utOmE2",
    "outputId": "76edf0d6-dc7d-46c5-b2c6-a6879b7cac51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the number of elements in the RDD with 'school'\n",
    "mydata = sc.textFile('./StudentsPerformance.txt')\n",
    "school_count = mydata.filter(lambda x: \"school\" in x).count()\n",
    "school_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8OkyU--WcZc",
    "outputId": "00372a95-a2b4-41c7-f242-13df80a45437"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the number of elements in the RDD with 'A', 'degree' and 'school'.\n",
    "All_count = A_count + degree_count + school_count\n",
    "All_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIy1IL965Ogm"
   },
   "source": [
    "## Question 4: Please utilize the following action RDD operation `sum` to compute how many times the word 'completed' appears in the given input file.\n",
    "\n",
    "sum() is an action type of RDD operation, which generate the sum of all the elements in RDD.\n",
    "For example: If rdd includes elements of 1, 2, and 3, rdd.sum() will return 6 as the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OmbLiCQ5ctu",
    "outputId": "93e890eb-de1c-4a4e-bd28-d3bcb09eb8a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question_4\n",
    "#Fill out here   # cannot use \"count\"\n",
    "  \n",
    "mydata = sc.textFile('./StudentsPerformance.txt')  #count = mydata.filter(lambda x: \"completed\" in x).count()\n",
    "mydata.map(lambda x: x.replace(\"\\\"\",\"\")).flatMap(lambda x: x.split(\",\")).map(lambda x: 1 if \"completed\" in x else 0).sum()   # Need use \"sum\", not \"count\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02102339_yz_Homework_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
